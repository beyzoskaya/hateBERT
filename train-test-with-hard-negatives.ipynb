{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.drop(columns=['annotaters'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['hate'] = df_clean['label'].map({'h': 1, 'nh': 0}) # binary hate, non-hate\n",
    "    \n",
    "    target_map = {'p': 0, 'e': 1, 'r': 2} # numeric mapping of target categories\n",
    "    df_clean['target'] = df_clean['target'].str.lower().str.strip()\n",
    "    \n",
    "    # non-hate labels have no target\n",
    "    df_clean['target'] = (\n",
    "        df_clean['target']\n",
    "        .map(target_map)\n",
    "        .where(df_clean['target'].isin(target_map.keys()))\n",
    "    )\n",
    "    df_clean['target'] = df_clean['target'].fillna(-100).astype(int)\n",
    "    \n",
    "    invalid_hate_mask = (df_clean['hate'] == 1) & (df_clean['target'] == -100)\n",
    "    df_clean.loc[invalid_hate_mask, 'hate'] = 0\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset(df):\n",
    "    assert set(df['hate'].unique()).issubset({0, 1}), f\"Invalid hate labels: {df['hate'].unique()}\"\n",
    "    \n",
    "    valid_targets = {-100, 0, 1, 2}\n",
    "    invalid_targets = set(df['target'].unique()) - valid_targets\n",
    "    assert not invalid_targets, f\"Invalid targets detected: {invalid_targets}\"\n",
    "    \n",
    "    nh_mask = df['hate'] == 0\n",
    "    assert (df.loc[nh_mask, 'target'] == -100).all(), \"Non-hate samples have invalid targets\"\n",
    "    \n",
    "    assert not df['text'].isna().any(), \"NaN in sentence column\"\n",
    "    assert not df['hate'].isna().any(), \"NaN in hate column\"\n",
    "    assert not df['target'].isna().any(), \"NaN in target column\"\n",
    "    \n",
    "    print(\"All dataset validation checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dataset validation checks passed!\n"
     ]
    }
   ],
   "source": [
    "df_clean = preprocess_data(df)\n",
    "\n",
    "validate_dataset(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3597"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/turkish-bert/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "class TurkishHateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, hate_labels, target_labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.hate_labels = hate_labels\n",
    "        self.target_labels = target_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'hate_labels': torch.tensor(self.hate_labels[idx], dtype=torch.float),\n",
    "            'target_labels': torch.tensor(self.target_labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurkishHateBERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "        self.hate_head = torch.nn.Linear(768, 1)\n",
    "        self.target_head = torch.nn.Linear(768, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.hate_head(pooled_output), self.target_head(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, tokenizer, batch_size=16):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['hate'])\n",
    "    \n",
    "    train_dataset = TurkishHateSpeechDataset(\n",
    "        train_df['text'].values,\n",
    "        train_df['hate'].values,\n",
    "        train_df['target'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    test_dataset = TurkishHateSpeechDataset(\n",
    "        test_df['text'].values,\n",
    "        test_df['hate'].values,\n",
    "        test_df['target'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "    return DataLoader(train_dataset, batch_size=batch_size, shuffle=True), \\\n",
    "           DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    hate_preds = []\n",
    "    hate_probs = []\n",
    "    true_hate = []\n",
    "    target_preds = []\n",
    "    true_target = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            hate_logits, target_logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Hate predictions\n",
    "            batch_probs = torch.sigmoid(hate_logits.squeeze()).cpu().numpy()\n",
    "            batch_preds = (batch_probs > 0.5).astype(int)\n",
    "            \n",
    "            hate_probs.extend(batch_probs)\n",
    "            hate_preds.extend(batch_preds)\n",
    "            true_hate.extend(batch['hate_labels'].cpu().numpy())\n",
    "            \n",
    "            # Target predictions\n",
    "            target_probs = torch.softmax(target_logits, dim=1).cpu().numpy()\n",
    "            batch_target_preds = np.argmax(target_probs, axis=1)\n",
    "            \n",
    "            target_preds.extend(batch_target_preds)\n",
    "            true_target.extend(batch['target_labels'].cpu().numpy())\n",
    "\n",
    "    # Filter target predictions for valid labels\n",
    "    target_mask = np.array(true_target) != -100\n",
    "    filtered_target_pred = np.array(target_preds)[target_mask]\n",
    "    filtered_true_target = np.array(true_target)[target_mask]\n",
    "\n",
    "    return {\n",
    "        'true_hate': true_hate,\n",
    "        'pred_hate': hate_preds,\n",
    "        'true_target': filtered_true_target,\n",
    "        'pred_target': filtered_target_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "import random\n",
    "\n",
    "turkish_augmenter = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-multilingual-cased',\n",
    "    action=\"substitute\",\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sentences(df, augmenter, aug_p=0.3, max_aug_per_sample=1):\n",
    "    augmented_rows = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if row['hate'] == 1 and random.random() < aug_p:\n",
    "            try:\n",
    "                for _ in range(max_aug_per_sample):\n",
    "                    aug_text = augmenter.augment(row['text'])\n",
    "                    if isinstance(aug_text, list):\n",
    "                        aug_text = aug_text[0]  # grab first if list returned\n",
    "                    new_row = row.copy()\n",
    "                    new_row['text'] = aug_text\n",
    "                    augmented_rows.append(new_row)\n",
    "            except Exception as e:\n",
    "                print(f\"Augmentation failed for row {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "    if augmented_rows:\n",
    "        aug_df = pd.DataFrame(augmented_rows)\n",
    "        print(f\"Added {len(aug_df)} augmented samples.\")\n",
    "        return pd.concat([df, aug_df], ignore_index=True)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 513 augmented samples.\n"
     ]
    }
   ],
   "source": [
    "df_augmented = augment_sentences(df_clean, turkish_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Gerçek bu kabullensenizde etmesenizde Akpnn es...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>Ya ne saçmalıyorsun amk üşüşmüş buraya sizin g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>&gt; KK'yı dinleye dinleye beyinleriniz uyuşmuş ,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>in. As as the way back, ben no gibi gözükmüyor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Bir de hep gördüğüm şey Kürdistan nErEsİ yA bE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  hate\n",
       "440   Gerçek bu kabullensenizde etmesenizde Akpnn es...     1\n",
       "2255  Ya ne saçmalıyorsun amk üşüşmüş buraya sizin g...     1\n",
       "2314  > KK'yı dinleye dinleye beyinleriniz uyuşmuş ,...     1\n",
       "3929  in. As as the way back, ben no gibi gözükmüyor...     1\n",
       "842   Bir de hep gördüğüm şey Kürdistan nErEsİ yA bE...     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented[['text', 'hate']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4110"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented.to_csv(\"augmented_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3288, Validation size: 822\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df_augmented, \n",
    "    test_size=0.2, \n",
    "    stratify=df_augmented['hate'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders_augmented(train_df, val_df, tokenizer, batch_size=16):\n",
    "    train_dataset = TurkishHateSpeechDataset(\n",
    "        train_df['text'].values,\n",
    "        train_df['hate'].values,\n",
    "        train_df['target'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    val_dataset = TurkishHateSpeechDataset(\n",
    "        val_df['text'].values,\n",
    "        val_df['hate'].values,\n",
    "        val_df['target'].values,\n",
    "        tokenizer\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hard_negatives(model, df_train, tokenizer, device, threshold=0.3, max_add=100):\n",
    "    model.eval()\n",
    "    non_hate_df = df_train[df_train['hate'] == 0].copy()\n",
    "\n",
    "    texts = non_hate_df['text'].tolist()\n",
    "    hate_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), 32):\n",
    "            batch_texts = texts[i:i+32]\n",
    "            encodings = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "            input_ids = encodings['input_ids'].to(device)\n",
    "            attention_mask = encodings['attention_mask'].to(device)\n",
    "\n",
    "            hate_logits, _ = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(hate_logits).detach().cpu().numpy().flatten()\n",
    "            hate_preds.extend(probs)\n",
    "    \n",
    "    non_hate_df['hate_prob'] = hate_preds\n",
    "    hard_negatives = non_hate_df[non_hate_df['hate_prob'] > threshold].copy()\n",
    "\n",
    "    hard_negatives = hard_negatives.sample(min(len(hard_negatives), max_add), random_state=42)\n",
    "    \n",
    "    print(f\"Adding {len(hard_negatives)} hard negatives to training data\")\n",
    "\n",
    "    df_new_train = pd.concat([df_train, hard_negatives], ignore_index=True)\n",
    "    return df_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_hard_neg(model, train_df, val_df, tokenizer, device, epochs=4, batch_size=16, lr=2e-5, threshold=0.3):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    hate_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    target_criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loader, val_loader = prepare_loaders_augmented(train_df, val_df, tokenizer, batch_size)\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            hate_labels = batch['hate_labels'].to(device)\n",
    "            target_labels = batch['target_labels'].to(device)\n",
    "            \n",
    "            hate_logits, target_logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            hate_loss = hate_criterion(hate_logits.squeeze(), hate_labels)\n",
    "            \n",
    "            target_mask = (target_labels != -100)\n",
    "            if target_mask.any():\n",
    "                target_loss = target_criterion(target_logits[target_mask], target_labels[target_mask])\n",
    "            else:\n",
    "                target_loss = torch.tensor(0.0).to(device)\n",
    "            \n",
    "            loss = hate_loss + target_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {total_loss/len(train_loader):.4f}\")\n",
    "        \n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        print(classification_report(val_metrics['true_hate'], val_metrics['pred_hate'], target_names=['Non-Hate', 'Hate']))\n",
    "        print(\"\\nTarget Classification (Hate Cases Only):\")\n",
    "        print(classification_report(val_metrics['true_target'], val_metrics['pred_target'], target_names=['Politics', 'Ethnicity', 'Religion']))\n",
    "        \n",
    "        # Add hard negatives for the next epoch training\n",
    "        train_df = add_hard_negatives(model, train_df, tokenizer, device, threshold=threshold)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/turkish-bert/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Train loss: 1.3963\n",
      "\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.76      0.59      0.67       392\n",
      "        Hate       0.69      0.83      0.75       430\n",
      "\n",
      "    accuracy                           0.72       822\n",
      "   macro avg       0.73      0.71      0.71       822\n",
      "weighted avg       0.72      0.72      0.71       822\n",
      "\n",
      "\n",
      "Target Classification (Hate Cases Only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.88      0.68      0.77       164\n",
      "   Ethnicity       0.82      0.79      0.80       187\n",
      "    Religion       0.56      0.87      0.68        79\n",
      "\n",
      "    accuracy                           0.76       430\n",
      "   macro avg       0.75      0.78      0.75       430\n",
      "weighted avg       0.80      0.76      0.77       430\n",
      "\n",
      "Adding 100 hard negatives to training data\n",
      "Epoch 2/4 - Train loss: 0.8914\n",
      "\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.73      0.82      0.77       392\n",
      "        Hate       0.81      0.73      0.77       430\n",
      "\n",
      "    accuracy                           0.77       822\n",
      "   macro avg       0.77      0.77      0.77       822\n",
      "weighted avg       0.77      0.77      0.77       822\n",
      "\n",
      "\n",
      "Target Classification (Hate Cases Only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.88      0.84      0.86       164\n",
      "   Ethnicity       0.84      0.87      0.86       187\n",
      "    Religion       0.75      0.77      0.76        79\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.83      0.83      0.83       430\n",
      "weighted avg       0.84      0.84      0.84       430\n",
      "\n",
      "Adding 100 hard negatives to training data\n",
      "Epoch 3/4 - Train loss: 0.5748\n",
      "\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.73      0.83      0.78       392\n",
      "        Hate       0.82      0.73      0.77       430\n",
      "\n",
      "    accuracy                           0.77       822\n",
      "   macro avg       0.78      0.78      0.77       822\n",
      "weighted avg       0.78      0.77      0.77       822\n",
      "\n",
      "\n",
      "Target Classification (Hate Cases Only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.82      0.88      0.85       164\n",
      "   Ethnicity       0.85      0.86      0.85       187\n",
      "    Religion       0.85      0.70      0.76        79\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.84      0.81      0.82       430\n",
      "weighted avg       0.84      0.84      0.84       430\n",
      "\n",
      "Adding 100 hard negatives to training data\n",
      "Epoch 4/4 - Train loss: 0.3175\n",
      "\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.78      0.81      0.80       392\n",
      "        Hate       0.82      0.79      0.81       430\n",
      "\n",
      "    accuracy                           0.80       822\n",
      "   macro avg       0.80      0.80      0.80       822\n",
      "weighted avg       0.80      0.80      0.80       822\n",
      "\n",
      "\n",
      "Target Classification (Hate Cases Only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.82      0.89      0.86       164\n",
      "   Ethnicity       0.89      0.80      0.84       187\n",
      "    Religion       0.78      0.84      0.80        79\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.83      0.84      0.83       430\n",
      "weighted avg       0.84      0.84      0.84       430\n",
      "\n",
      "Adding 45 hard negatives to training data\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "model = TurkishHateBERT()\n",
    "\n",
    "trained_model = train_model_with_hard_neg(\n",
    "    model,\n",
    "    train_df,  # (augmented + original)\n",
    "    val_df,    \n",
    "    tokenizer,\n",
    "    device,\n",
    "    epochs=4,\n",
    "    batch_size=16,\n",
    "    lr=2e-5,\n",
    "    threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_loader = prepare_loaders_augmented(train_df, val_df, tokenizer, batch_size=16)\n",
    "final_metrics = evaluate_model(trained_model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate Speech Detection (Binary):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.78      0.81      0.80       392\n",
      "        Hate       0.82      0.79      0.81       430\n",
      "\n",
      "    accuracy                           0.80       822\n",
      "   macro avg       0.80      0.80      0.80       822\n",
      "weighted avg       0.80      0.80      0.80       822\n",
      "\n",
      "\n",
      "Hate Target Classification (Multi-class, on hate samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.82      0.89      0.86       164\n",
      "   Ethnicity       0.89      0.80      0.84       187\n",
      "    Religion       0.78      0.84      0.80        79\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.83      0.84      0.83       430\n",
      "weighted avg       0.84      0.84      0.84       430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Hate Speech Detection (Binary):\")\n",
    "print(classification_report(final_metrics['true_hate'], final_metrics['pred_hate'], target_names=['Non-Hate', 'Hate']))\n",
    "\n",
    "print(\"\\nHate Target Classification (Multi-class, on hate samples only):\")\n",
    "print(classification_report(final_metrics['true_target'], final_metrics['pred_target'], target_names=['Politics', 'Ethnicity', 'Religion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 for Hate Detection: 0.8004\n",
      "Macro F1 for Target Classification: 0.8335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(final_metrics['true_hate'], final_metrics['pred_hate'], average='macro')\n",
    "print(f\"Macro F1 for Hate Detection: {f1:.4f}\")\n",
    "\n",
    "p_t, r_t, f1_t, _ = precision_recall_fscore_support(final_metrics['true_target'], final_metrics['pred_target'], average='macro')\n",
    "print(f\"Macro F1 for Target Classification: {f1_t:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model.state_dict(), 'turkish_hate_bert_with_hard_negatives.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wb/2d5zv5zx3sb06ttllws04nz80000gn/T/ipykernel_3868/865847263.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_baseline.load_state_dict(torch.load(\"dilbert_model_vanilla.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TurkishHateBERT(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (hate_head): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (target_head): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_baseline = TurkishHateBERT()\n",
    "model_baseline.load_state_dict(torch.load(\"dilbert_model_vanilla.pth\", map_location=torch.device('cpu')))\n",
    "model_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_baseline = evaluate_model(model_baseline, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate Speech Detection (Binary):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Hate       0.88      0.97      0.92       392\n",
      "        Hate       0.97      0.88      0.92       430\n",
      "\n",
      "    accuracy                           0.92       822\n",
      "   macro avg       0.92      0.92      0.92       822\n",
      "weighted avg       0.93      0.92      0.92       822\n",
      "\n",
      "\n",
      "Hate Target Classification (Multi-class, on hate samples only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Politics       0.94      0.94      0.94       164\n",
      "   Ethnicity       0.95      0.95      0.95       187\n",
      "    Religion       0.92      0.92      0.92        79\n",
      "\n",
      "    accuracy                           0.94       430\n",
      "   macro avg       0.94      0.94      0.94       430\n",
      "weighted avg       0.94      0.94      0.94       430\n",
      "\n",
      "Macro F1 for Hate Detection: 0.9221\n",
      "Macro F1 for Target Classification: 0.9384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "print(\"Hate Speech Detection (Binary):\")\n",
    "print(classification_report(final_metrics_baseline['true_hate'], final_metrics_baseline['pred_hate'], target_names=['Non-Hate', 'Hate']))\n",
    "\n",
    "print(\"\\nHate Target Classification (Multi-class, on hate samples only):\")\n",
    "print(classification_report(final_metrics_baseline['true_target'], final_metrics_baseline['pred_target'], target_names=['Politics', 'Ethnicity', 'Religion']))\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(final_metrics_baseline['true_hate'], final_metrics_baseline['pred_hate'], average='macro')\n",
    "print(f\"Macro F1 for Hate Detection: {f1:.4f}\")\n",
    "\n",
    "p_t, r_t, f1_t, _ = precision_recall_fscore_support(final_metrics_baseline['true_target'], final_metrics_baseline['pred_target'], average='macro')\n",
    "print(f\"Macro F1 for Target Classification: {f1_t:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turkish-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
